
import logging
import pprint
import lightgbm as lgb
from sklearn.metrics import auc, roc_curve
import streamlit as st

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import RandomizedSearchCV, train_test_split

from common_code import CommonCode

from controllers.data_builder import DatasetBuilder
from controllers.data_visualizer import DataVisualizer

from ui.dashboard_section import show_delinquency_ratio
from ui.dashboard_section import show_shap_analysis
from ui.dashboard_section import show_confusion_matrix
from ui.dashboard_section import show_performance_summary
from ui.dashboard_section import show_roc_curve


def run_scoring(builder: DatasetBuilder,visualizer : DataVisualizer, ê¸°ì¤€_ëŒ€ì¶œ, ë¹„êµ_ëŒ€ì¶œ, ì„ íƒë³€ìˆ˜, ì¡°íšŒì‹œì‘ë…„ì›”, ì¡°íšŒì¢…ë£Œë…„ì›”):

    logging.info("ì˜ˆì¸¡ëª¨ë¸ë§ ê°œìˆ˜")
    logging.info(len(builder.df_ì˜ˆì¸¡ëª¨ë¸ë§))
    logging.info(builder.df_ì˜ˆì¸¡ëª¨ë¸ë§.info())

    logging.info("ê¸°ì¤€ëŒ€ì¶œ : " + pprint.pformat(ê¸°ì¤€_ëŒ€ì¶œ))
    logging.info("ë¹„êµëŒ€ì¶œ : " + pprint.pformat(ë¹„êµ_ëŒ€ì¶œ))
    logging.info("ì„ íƒë³€ìˆ˜ : " + pprint.pformat(ì„ íƒë³€ìˆ˜))
    logging.info("ì„ íƒë³€ìˆ˜ : " + pprint.pformat(ì¡°íšŒì‹œì‘ë…„ì›”))
    logging.info("ì„ íƒë³€ìˆ˜ : " + pprint.pformat(ì¡°íšŒì¢…ë£Œë…„ì›”))

    #ê¸°ì¤€ì§‘ë‹¨
    df_base = builder.df_ì˜ˆì¸¡ëª¨ë¸ë§[
        (builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['LN_CD_1'] == str(ê¸°ì¤€_ëŒ€ì¶œ['ëŒ€ì¶œê³¼ëª©']['LN_CD_1']).lstrip('0')) &
        (builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['LN_CD_2'] == ê¸°ì¤€_ëŒ€ì¶œ['ëŒ€ì¶œê³¼ëª©']['LN_CD_2']) &
        (builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['LN_CD_3'] == ê¸°ì¤€_ëŒ€ì¶œ['ëŒ€ì¶œê³¼ëª©']['LN_CD_3']) &
        #(builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['ì§€ê¸‰ëŠ¥ë ¥_êµ¬ê°„'] == ê¸°ì¤€_ëŒ€ì¶œ['ì§€ê¸‰ëŠ¥ë ¥_êµ¬ê°„']) &
        (builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['RATE'] <= int(ê¸°ì¤€_ëŒ€ì¶œ['ê¸ˆë¦¬']*1000)) &
        (builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['LN_AMT'] <= ê¸°ì¤€_ëŒ€ì¶œ['ëŒ€ì¶œê¸ˆì•¡(ì²œì›)'])
    ]

    # ì¡°íšŒë…„ì›” í•„í„°ë§ 
    df_base = df_base[
        (df_base['YM'] >= int(ì¡°íšŒì‹œì‘ë…„ì›”)) &
        (df_base['YM'] <= int(ì¡°íšŒì¢…ë£Œë…„ì›”))
    ]

    #ë¹„êµì§‘ë‹¨
    df_comp = builder.df_ì˜ˆì¸¡ëª¨ë¸ë§[
        (builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['LN_CD_1'] == str(ë¹„êµ_ëŒ€ì¶œ['ëŒ€ì¶œê³¼ëª©']['LN_CD_1']).lstrip('0')) &
        (builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['LN_CD_2'] == ë¹„êµ_ëŒ€ì¶œ['ëŒ€ì¶œê³¼ëª©']['LN_CD_2']) &
        (builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['LN_CD_3'] == ë¹„êµ_ëŒ€ì¶œ['ëŒ€ì¶œê³¼ëª©']['LN_CD_3']) &
        #(builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['ì§€ê¸‰ëŠ¥ë ¥_êµ¬ê°„'] == ë¹„êµ_ëŒ€ì¶œ['ì§€ê¸‰ëŠ¥ë ¥_êµ¬ê°„']) &
        (builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['RATE'] <= int(ë¹„êµ_ëŒ€ì¶œ['ê¸ˆë¦¬']*1000)) &
        (builder.df_ì˜ˆì¸¡ëª¨ë¸ë§['LN_AMT'] <= int(ë¹„êµ_ëŒ€ì¶œ['ëŒ€ì¶œê¸ˆì•¡(ì²œì›)']))
    ]

    # ì¡°íšŒë…„ì›” í•„í„°ë§ 
    df_comp = df_comp[
        (df_comp['YM'] >= int(ì¡°íšŒì‹œì‘ë…„ì›”)) &
        (df_comp['YM'] <= int(ì¡°íšŒì¢…ë£Œë…„ì›”))
    ]

    logging.info("ê¸°ì¤€ëŒ€ì¶œ : "+pprint.pformat(df_base))
    logging.info("ë¹„êµëŒ€ì¶œ : "+pprint.pformat(df_comp))

    # ì°¨ì£¼ìˆ˜ ì œí•œ 
    if len(df_base) < 1000 or len(df_comp) < 1000:
        st.warning(f"""
        âš ï¸ ì§‘ë‹¨ì˜ row ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ì¡°ì •í•˜ì„¸ìš”.

        - ê¸°ì¤€ëŒ€ì¶œ: {len(df_base):,}ê±´  
        - ë¹„êµëŒ€ì¶œ: {len(df_comp):,}ê±´
        """)
        st.stop()  # ì´í›„ ì‹¤í–‰ ì¤‘ë‹¨
    else : 
        with st.container():
            st.markdown("### ğŸ“Œ ë°ì´í„° ê±´ìˆ˜ ìš”ì•½")
            st.markdown(f"""
            - **ê¸°ì¤€ëŒ€ì¶œ:** {len(df_base):,}ê±´  
            - **ë¹„êµëŒ€ì¶œ:** {len(df_comp):,}ê±´
            """)

            st.markdown("### ğŸ§¾ ê¸°ì¤€ëŒ€ì¶œ ì¡°íšŒì¡°ê±´")
            st.code(pprint.pformat(ê¸°ì¤€_ëŒ€ì¶œ), language="python")

            st.markdown("### ğŸ§¾ ë¹„êµëŒ€ì¶œ ì¡°íšŒì¡°ê±´")
            st.code(pprint.pformat(ë¹„êµ_ëŒ€ì¶œ), language="python")

            st.markdown("### ğŸ§¾ ì„ íƒë³€ìˆ˜")
            st.code(ì„ íƒë³€ìˆ˜, language="python")

    # ë¨¸ì‹ ëŸ¬ë‹ ì‹¤í–‰
    X_base_train, X_base_test, y_base_train, y_base_test = train_test_split(
        df_base[ì„ íƒë³€ìˆ˜], df_base['DLQ_YN'], test_size=0.2, random_state=42)

    X_comp_train, X_comp_test, y_comp_train, y_comp_test = train_test_split(
        df_comp[ì„ íƒë³€ìˆ˜], df_comp['DLQ_YN'], test_size=0.2, random_state=42)
    

    # âœ… 2. ì˜¤ë²„ìƒ˜í”Œë§ (SMOTE)
    smote = SMOTE(random_state=42)

    X_base_train_res, y_base_train_res = smote.fit_resample(X_base_train, y_base_train)
    X_comp_train_res, y_comp_train_res = smote.fit_resample(X_comp_train, y_comp_train)

    # âœ… 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (RandomizedSearchCV)
    param_grid = {
        'n_estimators': [100, 200],
        'learning_rate': [0.05, 0.1],
        'num_leaves': [15, 31],
        'max_depth': [3, 5],
        'min_child_samples': [10, 20],
        'subsample': [0.8],
        'colsample_bytree': [0.8]
    }

    clf_base = RandomizedSearchCV(
        estimator=lgb.LGBMClassifier(random_state=42),
        param_distributions=param_grid,
        n_iter=3,  # íƒìƒ‰ íšŸìˆ˜
        cv=2,
        scoring='roc_auc',
        verbose=1,
        random_state=42,
        n_jobs=-1
    )

    clf_comp = RandomizedSearchCV(
        estimator=lgb.LGBMClassifier(random_state=42),
        param_distributions=param_grid,
        n_iter=3,
        cv=2,
        scoring='roc_auc',
        verbose=1,
        random_state=42,
        n_jobs=-1
    )

    # âœ… 4. ëª¨ë¸ í•™ìŠµ
    clf_base.fit(X_base_train_res, y_base_train_res)
    clf_comp.fit(X_comp_train_res, y_comp_train_res)

    # ì˜ˆì¸¡ í™•ë¥ 
    y_base_proba = clf_base.predict_proba(X_base_test)[:, 1]
    y_comp_proba = clf_comp.predict_proba(X_comp_test)[:, 1]

    # ROC ê³„ì‚°
    fpr_base, tpr_base, _ = roc_curve(y_base_test, y_base_proba)
    roc_auc_base = auc(fpr_base, tpr_base)

    fpr_comp, tpr_comp, _ = roc_curve(y_comp_test, y_comp_proba)
    roc_auc_comp = auc(fpr_comp, tpr_comp)

    # ì‹œê°í™” 

    # íƒ­ ìƒì„±
    # css ì£¼ì…
    st.markdown("""
    <style>
    /* íƒ­ ì˜ì—­ ì „ì²´ ìŠ¤íƒ€ì¼ */
    div[data-baseweb="tab-list"] {
        font-size: 20px !important;    /* ê¸€ì í¬ê¸° */
        height: 60px;                  /* íƒ­ ë†’ì´ */
    }

    /* ê° íƒ­ ë²„íŠ¼ì˜ ìŠ¤íƒ€ì¼ */
    button[role="tab"] {
        padding: 12px 24px !important;  /* ë‚´ë¶€ ì—¬ë°± */
        font-size: 18px !important;     /* ê¸€ì í¬ê¸° */
        font-weight: bold !important;
        color: white !important;
        background-color: #1c1c1c !important;
        border-radius: 8px !important;
        margin-right: 10px !important;
    }

    /* ì„ íƒëœ íƒ­ ìŠ¤íƒ€ì¼ */
    button[aria-selected="true"] {
        background-color: #0e76a8 !important; /* ì„ íƒëœ íƒ­ ë°°ê²½ìƒ‰ */
        color: white !important;
    }
    </style>
    """, unsafe_allow_html=True)

    íƒ­1, íƒ­2, íƒ­3 = st.tabs(["ğŸ“ˆ ì—°ì²´ìœ¨ ì¶”ì´", "ğŸ” ë³€ìˆ˜ì¤‘ìš”ë„ ë¹„êµ", "ğŸ” ROC-Curve"])

    # ì²« ë²ˆì§¸ íƒ­: ì—°ì²´ìœ¨ ì¶”ì´
    with íƒ­1:
        st.subheader("ì—°ì²´ìœ¨ ì¶”ì´")
        show_delinquency_ratio(df_base, df_comp, ì¡°íšŒì‹œì‘ë…„ì›”, ì¡°íšŒì¢…ë£Œë…„ì›”)

    # ë‘ ë²ˆì§¸ íƒ­: ë³€ìˆ˜ì¤‘ìš”ë„
    with íƒ­2:
        st.subheader("ë³€ìˆ˜ì¤‘ìš”ë„ ë¹„êµ")
        show_shap_analysis(clf_base.best_estimator_, clf_comp.best_estimator_, X_base_test, X_comp_test)

        st.subheader("ê¸°ì¤€ëŒ€ì¶œ ë³€ìˆ˜ì¤‘ìš”ë„(Matrix)")
        show_performance_summary(clf_base.best_estimator_,ì„ íƒë³€ìˆ˜,X_base_test,y_base_test,y_base_proba)

        st.subheader("ë¹„êµëŒ€ì¶œ ë³€ìˆ˜ì¤‘ìš”ë„(Matrix)")
        show_performance_summary(clf_comp.best_estimator_,ì„ íƒë³€ìˆ˜,X_comp_test,y_comp_test,y_comp_proba)

    with íƒ­3:
        st.subheader("ROC Curve")
        show_roc_curve(fpr_base,tpr_base,fpr_comp,tpr_comp,roc_auc_base,roc_auc_comp)

        st.subheader("Confusion Matrix(ê¸°ì¤€ëŒ€ì¶œ)")
        show_confusion_matrix(clf_base,X_base_test,y_base_test)

        st.subheader("Confusion Matrix(ë¹„êµëŒ€ì¶œ)")
        show_confusion_matrix(clf_comp,X_comp_test,y_comp_test)